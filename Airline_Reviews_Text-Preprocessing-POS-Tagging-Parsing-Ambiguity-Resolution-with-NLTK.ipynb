{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63531ae2-528a-47ed-b922-2a6cc7eed509",
   "metadata": {},
   "source": [
    "# Airline Customer Review Analysis using NLP: Text Preprocessing, POS Tagging, Parsing & Ambiguity Resolution with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766fd63f-9945-437b-a550-4044ee9fdffe",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41366e9a-0647-49a5-b2c5-021ab600c4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import time\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import CFG\n",
    "from nltk.corpus import stopwords\n",
    "from tabulate import tabulate\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk import pos_tag, CFG, ChartParser, RecursiveDescentParser, ShiftReduceParser, word_tokenize, sent_tokenize, Tree\n",
    "from nltk.parse import RecursiveDescentParser, ShiftReduceParser\n",
    "from IPython.display import Markdown, display ,SVG ,HTML\n",
    "from nltk.parse.chart import TopDownChartParser, BottomUpChartParser\n",
    "import pandas as pd\n",
    "\n",
    "#  Download NLTK resources\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"punkt_tab\", quiet=True)\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "nltk.download(\"averaged_perceptron_tagger_eng\", quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ab0054-b95a-4fc7-afab-a584f4ac713a",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3a5f3a-86ea-4ccb-9277-36a36b0e65a7",
   "metadata": {},
   "source": [
    "# TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67360e7e-a606-4f3e-9507-cb9cc9989bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style='font-size:100%; font-weight:bold; text-decoration:underline;'>TASK 1 :</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer review in original form</th>\n",
       "      <th>After removing punctuations, special characters &amp; stopwords</th>\n",
       "      <th>After converting to lowercase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>âœ… Trip Verified | London to Izmir via Istanb...</td>\n",
       "      <td>Trip Verified London Izmir via Istanbul First ...</td>\n",
       "      <td>trip verified london izmir via istanbul first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>âœ… Trip Verified | Istanbul to Bucharest. We ...</td>\n",
       "      <td>Trip Verified Istanbul Bucharest make check ai...</td>\n",
       "      <td>trip verified istanbul bucharest make check ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>âœ… Trip Verified | Rome to Prishtina via Ista...</td>\n",
       "      <td>Trip Verified Rome Prishtina via Istanbul flew...</td>\n",
       "      <td>trip verified rome prishtina via istanbul flew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>âœ… Trip Verified | Flew on Turkish Airlines I...</td>\n",
       "      <td>Trip Verified Flew Turkish Airlines IAD IST KH...</td>\n",
       "      <td>trip verified flew turkish airlines iad ist kh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>âœ… Trip Verified | Mumbai to Dublin via Istan...</td>\n",
       "      <td>Trip Verified Mumbai Dublin via Istanbul Never...</td>\n",
       "      <td>trip verified mumbai dublin via istanbul never...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Customer review in original form  \\\n",
       "0  âœ… Trip Verified | London to Izmir via Istanb...   \n",
       "1  âœ… Trip Verified | Istanbul to Bucharest. We ...   \n",
       "2  âœ… Trip Verified | Rome to Prishtina via Ista...   \n",
       "3  âœ… Trip Verified | Flew on Turkish Airlines I...   \n",
       "4  âœ… Trip Verified | Mumbai to Dublin via Istan...   \n",
       "\n",
       "  After removing punctuations, special characters & stopwords  \\\n",
       "0  Trip Verified London Izmir via Istanbul First ...            \n",
       "1  Trip Verified Istanbul Bucharest make check ai...            \n",
       "2  Trip Verified Rome Prishtina via Istanbul flew...            \n",
       "3  Trip Verified Flew Turkish Airlines IAD IST KH...            \n",
       "4  Trip Verified Mumbai Dublin via Istanbul Never...            \n",
       "\n",
       "                       After converting to lowercase  \n",
       "0  trip verified london izmir via istanbul first ...  \n",
       "1  trip verified istanbul bucharest make check ai...  \n",
       "2  trip verified rome prishtina via istanbul flew...  \n",
       "3  trip verified flew turkish airlines iad ist kh...  \n",
       "4  trip verified mumbai dublin via istanbul never...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have download the file in local machine and setting it as the DataFrame.\n",
      "We successfully cleaned punctuations, special characters, and stopwords from 'customer_review'.\n",
      "Finally, we converted the cleaned text to lowercase and displayed the first 5 processed rows in tabular form.\n"
     ]
    }
   ],
   "source": [
    "# Load data file from local machine and set as dataframe\n",
    "file_path = r\"C:\\Users\\BITSprem007\\Downloads\\NLP\\capstone_airline_reviews3.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Drop blank/null rows from 'customer_review'\n",
    "df = df.dropna(subset=[\"customer_review\"])\n",
    "df = df[df[\"customer_review\"].str.strip().astype(bool)]\n",
    "\n",
    "# Define stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Step 1: Remove punctuations, special characters & stopwords\n",
    "def clean_text_no_lower(text):\n",
    "    text = str(text)\n",
    "    # Remove encoded junk\n",
    "    text = text.encode(\"utf-8\", \"ignore\").decode(\"utf-8\", \"ignore\")\n",
    "    # Remove punctuations & special characters\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    tokens = [w for w in tokens if w.lower() not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"removed_punct_stop\"] = df[\"customer_review\"].apply(clean_text_no_lower)\n",
    "\n",
    "# Step 2: Convert to lowercase\n",
    "df[\"lower_case_review\"] = df[\"removed_punct_stop\"].str.lower()\n",
    "\n",
    "# Final output\n",
    "display(HTML(\"<span style='font-size:100%; font-weight:bold; text-decoration:underline;'>TASK 1 :</span>\"))\n",
    "\n",
    "# Rename columns for display\n",
    "subset = df.rename(columns={\n",
    "    \"customer_review\": \"Customer review in original form\",\n",
    "    \"removed_punct_stop\": \"After removing punctuations, special characters & stopwords\",\n",
    "    \"lower_case_review\": \"After converting to lowercase\"\n",
    "})[[\n",
    "    \"Customer review in original form\",\n",
    "    \"After removing punctuations, special characters & stopwords\",\n",
    "    \"After converting to lowercase\"\n",
    "]].head(5).reset_index(drop=True)\n",
    "\n",
    "display(subset)\n",
    "\n",
    "# Final Answer Statement\n",
    "print(\"We have download the file in local machine and setting it as the DataFrame.\")\n",
    "print(\"We successfully cleaned punctuations, special characters, and stopwords from 'customer_review'.\")\n",
    "print(\"Finally, we converted the cleaned text to lowercase and displayed the first 5 processed rows in tabular form.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92630795-ebb9-4c5b-983f-1d22f69054e8",
   "metadata": {},
   "source": [
    "# TASK 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7b9c66-5f1c-44a6-8ec3-8f1c19dbec6d",
   "metadata": {},
   "source": [
    "## Task 2.1 POS Tagging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0366fab0-87b7-442f-ac12-14b22496c40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### POS tagging on the last 2 rows of customer_review"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Customer Review:** several flights kbp ams times one way lgw r zrh twice one way txl kbp mixed experience yelled tried correct agent pronunciation phoenix final destination day time misplaced onward zrh lax tickets wife two kids agent thought gave someone else mistake ran looking even though tried explaining must placed somewhere desk fact guys tried make giving us passes kbp business class lounge simply time go run straight gate delay otherwise average service newer planes even started smiling"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**POS Tags:** [('several', 'JJ'), ('flights', 'NNS'), ('kbp', 'VBD'), ('ams', 'JJ'), ('times', 'NNS'), ('one', 'CD'), ('way', 'NN'), ('lgw', 'VBZ'), ('r', 'NN'), ('zrh', 'NN'), ('twice', 'RB'), ('one', 'CD'), ('way', 'NN'), ('txl', 'NN'), ('kbp', 'VB'), ('mixed', 'JJ'), ('experience', 'NN'), ('yelled', 'VBD'), ('tried', 'JJ'), ('correct', 'JJ'), ('agent', 'NN'), ('pronunciation', 'NN'), ('phoenix', 'IN'), ('final', 'JJ'), ('destination', 'NN'), ('day', 'NN'), ('time', 'NN'), ('misplaced', 'VBN'), ('onward', 'RB'), ('zrh', 'JJ'), ('lax', 'JJ'), ('tickets', 'NNS'), ('wife', 'NN'), ('two', 'CD'), ('kids', 'NNS'), ('agent', 'JJ'), ('thought', 'VBN'), ('gave', 'VBD'), ('someone', 'NN'), ('else', 'RB'), ('mistake', 'NN'), ('ran', 'VBD'), ('looking', 'VBG'), ('even', 'RB'), ('though', 'IN'), ('tried', 'JJ'), ('explaining', 'VBG'), ('must', 'MD'), ('placed', 'VBN'), ('somewhere', 'RB'), ('desk', 'JJ'), ('fact', 'NN'), ('guys', 'NNS'), ('tried', 'VBD'), ('make', 'VBP'), ('giving', 'VBG'), ('us', 'PRP'), ('passes', 'VBZ'), ('kbp', 'NN'), ('business', 'NN'), ('class', 'NN'), ('lounge', 'NN'), ('simply', 'RB'), ('time', 'NN'), ('go', 'VB'), ('run', 'RB'), ('straight', 'RB'), ('gate', 'JJ'), ('delay', 'NN'), ('otherwise', 'RB'), ('average', 'JJ'), ('service', 'NN'), ('newer', 'NN'), ('planes', 'NNS'), ('even', 'RB'), ('started', 'VBD'), ('smiling', 'VBG')]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Customer Review:** kbp ams uia although relatively short flight good meal drinks served staff friendly seating ok looking price ticket think well worth money spend"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**POS Tags:** [('kbp', 'NN'), ('ams', 'NNS'), ('uia', 'VBP'), ('although', 'IN'), ('relatively', 'RB'), ('short', 'JJ'), ('flight', 'NN'), ('good', 'JJ'), ('meal', 'NN'), ('drinks', 'NNS'), ('served', 'VBD'), ('staff', 'NN'), ('friendly', 'RB'), ('seating', 'VBG'), ('ok', 'RP'), ('looking', 'VBG'), ('price', 'NN'), ('ticket', 'NN'), ('think', 'VBP'), ('well', 'RB'), ('worth', 'JJ'), ('money', 'NN'), ('spend', 'NN')]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the last 2 reviews from Task 1\n",
    "reviews_column = df['lower_case_review'].tail(2).reset_index(drop=True)\n",
    "\n",
    "# POS Tagging\n",
    "display(Markdown(\"### POS tagging on the last 2 rows of customer_review\"))\n",
    "\n",
    "for review in reviews_column:\n",
    "    # Display the full review as header\n",
    "    display(Markdown(f\"**Customer Review:** {review}\"))\n",
    "    \n",
    "    # Tokenize review into words\n",
    "    tokens = word_tokenize(review)\n",
    "    tags = pos_tag(tokens)\n",
    "    \n",
    "    display(Markdown(f\"**POS Tags:** {tags}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1ee13d-4241-440c-9add-ee1a694c2df9",
   "metadata": {},
   "source": [
    "## Task 2.2 & 2.3  Parsing + Visual Tree + Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5fbff08b-6900-43a0-afb8-47a1d8f5bba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Parsing Sentences Using Top-Down & Bottom-Up Methods"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Review 1 Parsing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Review 1 CFG:\n",
       "```\n",
       "S -> JJ NNS VBD JJ NNS CD NN VBZ NN NN RB CD NN NN VB JJ NN VBD JJ JJ\n",
       "JJ -> 'several'\n",
       "NNS -> 'flights'\n",
       "VBD -> 'kbp'\n",
       "JJ -> 'ams'\n",
       "NNS -> 'times'\n",
       "CD -> 'one'\n",
       "NN -> 'way'\n",
       "VBZ -> 'lgw'\n",
       "NN -> 'r'\n",
       "NN -> 'zrh'\n",
       "RB -> 'twice'\n",
       "CD -> 'one'\n",
       "NN -> 'way'\n",
       "NN -> 'txl'\n",
       "VB -> 'kbp'\n",
       "JJ -> 'mixed'\n",
       "NN -> 'experience'\n",
       "VBD -> 'yelled'\n",
       "JJ -> 'tried'\n",
       "JJ -> 'correct'\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Top-Down Parse Tree:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               S                                                             \n",
      "    ___________________________________________|_________________________________________________________     \n",
      "   JJ     NNS   VBD  JJ  NNS   CD  NN VBZ  NN  NN   RB   CD  NN  NN  VB   JJ      NN      VBD     JJ     JJ  \n",
      "   |       |     |   |    |    |   |   |   |   |    |    |   |   |   |    |       |        |      |      |    \n",
      "several flights kbp ams times one way lgw  r  zrh twice one way txl kbp mixed experience yelled tried correct\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Bottom-Up Parse Tree:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               S                                                             \n",
      "    ___________________________________________|_________________________________________________________     \n",
      "   JJ     NNS   VBD  JJ  NNS   CD  NN VBZ  NN  NN   RB   CD  NN  NN  VB   JJ      NN      VBD     JJ     JJ  \n",
      "   |       |     |   |    |    |   |   |   |   |    |    |   |   |   |    |       |        |      |      |    \n",
      "several flights kbp ams times one way lgw  r  zrh twice one way txl kbp mixed experience yelled tried correct\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Review 2 Parsing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Review 2 CFG:\n",
       "```\n",
       "S -> NN NNS VBP IN RB JJ NN JJ NN NNS VBD NN RB VBG RP\n",
       "NN -> 'kbp'\n",
       "NNS -> 'ams'\n",
       "VBP -> 'uia'\n",
       "IN -> 'although'\n",
       "RB -> 'relatively'\n",
       "JJ -> 'short'\n",
       "NN -> 'flight'\n",
       "JJ -> 'good'\n",
       "NN -> 'meal'\n",
       "NNS -> 'drinks'\n",
       "VBD -> 'served'\n",
       "NN -> 'staff'\n",
       "RB -> 'friendly'\n",
       "VBG -> 'seating'\n",
       "RP -> 'ok'\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Top-Down Parse Tree:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              S                                                \n",
      "  ____________________________________________|______________________________________________   \n",
      " NN NNS VBP    IN        RB       JJ    NN    JJ   NN   NNS    VBD     NN     RB      VBG    RP\n",
      " |   |   |     |         |        |     |     |    |     |      |      |      |        |     |  \n",
      "kbp ams uia although relatively short flight good meal drinks served staff friendly seating  ok\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Bottom-Up Parse Tree:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              S                                                \n",
      "  ____________________________________________|______________________________________________   \n",
      " NN NNS VBP    IN        RB       JJ    NN    JJ   NN   NNS    VBD     NN     RB      VBG    RP\n",
      " |   |   |     |         |        |     |     |    |     |      |      |      |        |     |  \n",
      "kbp ams uia although relatively short flight good meal drinks served staff friendly seating  ok\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Efficiency Comparison"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Top-Down Time (s)</th>\n",
       "      <th>Bottom-Up Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>0.003944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.001802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Review  Tokens  Top-Down Time (s)  Bottom-Up Time (s)\n",
       "0       1      20           0.003913            0.003944\n",
       "1       2      15           0.002607            0.001802"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==============================\n",
    "# Task 2: POS Tagging and Parsing (Without Operation Count)\n",
    "# ==============================\n",
    "\n",
    "import nltk\n",
    "from nltk import CFG\n",
    "from nltk.parse.chart import TopDownChartParser, BottomUpChartParser\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"averaged_perceptron_tagger\", quiet=True)\n",
    "\n",
    "# Pick last 2 reviews\n",
    "sample_reviews = df[\"lower_case_review\"].tail(2).reset_index(drop=True)\n",
    "token_limits = [20, 15]  # Token limit for each review\n",
    "\n",
    "display(Markdown(\"### Parsing Sentences Using Top-Down & Bottom-Up Methods\"))\n",
    "\n",
    "efficiency_results = []\n",
    "\n",
    "for i, review in enumerate(sample_reviews, 1):\n",
    "    display(Markdown(f\"## Review {i} Parsing\"))\n",
    "    tokens = word_tokenize(review)\n",
    "    tags = pos_tag(tokens)\n",
    "\n",
    "    # Filter alphabetic tokens\n",
    "    alpha_tags = [(w, p) for w, p in tags if w.isalpha()]\n",
    "    if not alpha_tags:\n",
    "        continue\n",
    "\n",
    "    # Limit tokens according to predefined limits\n",
    "    alpha_tags = alpha_tags[:token_limits[i-1]]\n",
    "\n",
    "    # Build simple CFG: S -> POS POS ...\n",
    "    pos_sequence = \" \".join(p for _, p in alpha_tags)\n",
    "    grammar_rules = [f\"S -> {pos_sequence}\"]\n",
    "    for w, p in alpha_tags:\n",
    "        grammar_rules.append(f\"{p} -> '{w}'\")\n",
    "    grammar_text = \"\\n\".join(grammar_rules)\n",
    "\n",
    "    try:\n",
    "        grammar = CFG.fromstring(grammar_text)\n",
    "    except Exception as e:\n",
    "        display(Markdown(f\" Skipping review {i} due to CFG error: {e}\"))\n",
    "        continue\n",
    "\n",
    "    # ---------------- Top-Down Parser ----------------\n",
    "    td_parser = TopDownChartParser(grammar)\n",
    "    t0 = time.time()\n",
    "    td_trees = list(td_parser.parse([w for w, _ in alpha_tags]))\n",
    "    td_time = time.time() - t0\n",
    "\n",
    "    # ---------------- Bottom-Up Parser ----------------\n",
    "    bu_parser = BottomUpChartParser(grammar)\n",
    "    t1 = time.time()\n",
    "    bu_trees = list(bu_parser.parse([w for w, _ in alpha_tags]))\n",
    "    bu_time = time.time() - t1\n",
    "\n",
    "    # Display CFG\n",
    "    display(Markdown(f\"### Review {i} CFG:\\n```\\n{grammar_text}\\n```\"))\n",
    "\n",
    "    # Display Parse Trees\n",
    "    if td_trees:\n",
    "        display(Markdown(\"**Top-Down Parse Tree:**\"))\n",
    "        td_trees[0].pretty_print()\n",
    "        # td_trees[0].draw()  # Uncomment to open tree GUI\n",
    "\n",
    "    if bu_trees:\n",
    "        display(Markdown(\"**Bottom-Up Parse Tree:**\"))\n",
    "        bu_trees[0].pretty_print()\n",
    "        # bu_trees[0].draw()  # Uncomment to open tree GUI\n",
    "\n",
    "    # Track efficiency (time only)\n",
    "    efficiency_results.append({\n",
    "        'Review': i,\n",
    "        'Tokens': len(alpha_tags),\n",
    "        'Top-Down Time (s)': td_time,\n",
    "        'Bottom-Up Time (s)': bu_time\n",
    "    })\n",
    "\n",
    "# Display efficiency comparison\n",
    "display(Markdown(\"### Efficiency Comparison\"))\n",
    "efficiency_df = pd.DataFrame(efficiency_results)\n",
    "display(efficiency_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dce442-ff70-492d-92be-147960bb81ff",
   "metadata": {},
   "source": [
    "##### In Task 2, the last two customer reviews were analyzed. All words in each review were first processed with POS tagging to map tokens to their parts of speech. Simple CFGs were then created using the first 20 tokens from the first review and 15 tokens from the second. Both Top-Down and Bottom-Up parsing methods were applied, and their parse trees were visualized, showing identical structures due to the straightforward, deterministic grammar. Finally, an efficiency comparison table captured the parsing times, indicating that both methods performed efficiently, with minor differences in speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280a9266-ef2b-493c-be3d-66f2dcbb881f",
   "metadata": {},
   "source": [
    "# TASK 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d64de2-56a6-468e-b600-c6eedc30fe3b",
   "metadata": {},
   "source": [
    "### Ambiguity is a common challenge in parsing natural language sentences. Consider the sentence \"Time flies like an arrow.\" This sentence can be ambiguous or misleading due to its multiple possible interpretations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d6f758-1c71-4d2f-939a-42035698f85d",
   "metadata": {},
   "source": [
    "#### 1 .Explain the source of ambiguity in this sentence and how it poses a challenge to standard CFGs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032ce82c-eaa8-4aef-b05f-a90fe778f116",
   "metadata": {},
   "source": [
    "The sentence “Time flies like an arrow” is ambiguous because several words can function as different parts of speech depending on interpretation. For example, “Time” can be a noun (referring to the concept of time) or a verb (meaning to measure duration), and “flies” can be a verb (to move quickly) or a noun (insects). Additionally, “like an arrow” can modify either the verb “flies” or describe a method for measuring. This results in multiple valid readings, such as:\n",
    "\n",
    "“Time moves quickly, similar to an arrow” (literal meaning).\n",
    "\n",
    "“Measure flies in the same way you would measure an arrow” (imperative meaning).\n",
    "\n",
    "“Time flies that behave like an arrow” (noun phrase interpretation).\n",
    "\n",
    "Standard context-free grammars (CFGs) are limited in handling such cases because they assume a fixed, single parse structure. As a result, a CFG might produce incorrect parses, fail to account for all possible interpretations, or generate ambiguous trees that do not reflect the intended meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849a8c23-9ffd-4579-9979-c2499a386e3c",
   "metadata": {},
   "source": [
    "#### 2.\tPropose a modification to a CFG that could correctly parse this sentence without leading to incorrect interpretations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ecf81c4-d5d7-43a0-bf0e-4e0aff671219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### CFG used:\n",
       "```\n",
       "\n",
       "S -> NP VP\n",
       "NP -> N | N N | Det N\n",
       "VP -> V NP | V NP PP | V\n",
       "PP -> P NP\n",
       "Det -> 'an'\n",
       "N -> 'Time' | 'flies' | 'arrow'\n",
       "V -> 'flies' | 'like'\n",
       "P -> 'like'\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Parse Tree 1:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                S                \n",
      "       _________|____             \n",
      "      |              VP          \n",
      "      |          ____|___         \n",
      "      NP        |        NP      \n",
      "  ____|____     |     ___|____    \n",
      " N         N    V   Det       N  \n",
      " |         |    |    |        |   \n",
      "Time     flies like  an     arrow\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import CFG, ChartParser\n",
    "from nltk.tokenize import word_tokenize\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Sentence\n",
    "sentence = \"Time flies like an arrow\"\n",
    "tokens = word_tokenize(sentence)\n",
    "\n",
    "# Modified CFG to handle multiple interpretations\n",
    "grammar_text = \"\"\"\n",
    "S -> NP VP\n",
    "NP -> N | N N | Det N\n",
    "VP -> V NP | V NP PP | V\n",
    "PP -> P NP\n",
    "Det -> 'an'\n",
    "N -> 'Time' | 'flies' | 'arrow'\n",
    "V -> 'flies' | 'like'\n",
    "P -> 'like'\n",
    "\"\"\"\n",
    "\n",
    "grammar = CFG.fromstring(grammar_text)\n",
    "\n",
    "# Create parser\n",
    "parser = ChartParser(grammar)\n",
    "\n",
    "# Parse the sentence\n",
    "trees = list(parser.parse(tokens))\n",
    "\n",
    "# Display CFG\n",
    "display(Markdown(f\"### CFG used:\\n```\\n{grammar_text}\\n```\"))\n",
    "\n",
    "# Display all parse trees\n",
    "if trees:\n",
    "    for i, tree in enumerate(trees, 1):\n",
    "        display(Markdown(f\"**Parse Tree {i}:**\"))\n",
    "        tree.pretty_print()\n",
    "        tree.draw()\n",
    "else:\n",
    "    display(Markdown(\"No parse tree could be generated.\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5466abc6-5a7e-4935-af70-e5127aa2eda5",
   "metadata": {},
   "source": [
    "In this code, the sentence “Time flies like an arrow” is tokenized and parsed using a modified CFG designed to handle the inherent ambiguity. The grammar defines rules for noun phrases (NP), verb phrases (VP), and prepositional phrases (PP), allowing words like \"flies\" and \"like\" to function as both verbs and nouns, depending on context. For example, \"Time\" and \"flies\" can form a compound noun phrase, while \"like an arrow\" can be interpreted as a VP containing a prepositional phrase.\n",
    "\n",
    "The modification in the CFG (compared to a standard CFG) includes additional NP and VP production rules, such as:\n",
    "\n",
    "NP -> N N to allow compound nouns like \"Time flies\".\n",
    "\n",
    "VP -> V NP PP | V to accommodate sentences where \"like\" is a verb or a preposition introducing a prepositional phrase.\n",
    "\n",
    "By explicitly including these variations, the parser can generate correct parse trees for the sentence without producing invalid interpretations. The code then uses NLTK’s ChartParser to generate all possible parse trees according to this CFG and visually displays them, demonstrating how the CFG handles ambiguity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcde36c-4a67-423b-a155-1916a135196a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
